{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772c2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class VLPForFeatureExtraction(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_dim,\n",
    "                 num_layers,\n",
    "                 num_heads,\n",
    "                 ff_dim,\n",
    "                 feature_map_size,\n",
    "                 dropout=0.0,\n",
    "                 dec_div=2):\n",
    "        super(VLPForFeatureExtraction, self).__init__()\n",
    "\n",
    "        self.vlp = VLP(num_layers=num_layers,\n",
    "                       model_dim=model_dim,\n",
    "                       ff_dim=ff_dim,\n",
    "                       num_heads=num_heads,\n",
    "                       feature_map_size=feature_map_size,\n",
    "                       vocab_size=None,\n",
    "                       dropout=dropout,\n",
    "                       transformer_type=\"encoder\",\n",
    "                       dec_div=dec_div)\n",
    "\n",
    "    def forward(self, images):\n",
    "        out = self.vlp(images)\n",
    "        return out.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d05ceca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VLPForFeatureExtraction(\n",
       "  (vlp): VLP(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): ResNetFeatureExtractor(\n",
       "        (feature_extractor): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_proj): Conv2d(2048, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SinePositionalEncoding()\n",
       "    )\n",
       "    (transformer): EncoderDecoder(\n",
       "      (encoder): Encoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (8): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (9): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (10): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (11): EncoderLayer(\n",
       "            (self_attn): MultiHeadAttention(\n",
       "              (linears): ModuleList(\n",
       "                (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (feed_forward): PositionwiseFeedForward(\n",
       "              (w_1): Linear(in_features=768, out_features=4096, bias=True)\n",
       "              (w_2): Linear(in_features=4096, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (sublayer): ModuleList(\n",
       "              (0): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (1): SublayerConnection(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (decoder): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from model.vlp import VLP, model_config_factory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_tokenizer():\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "    special_tokens_dict = {'additional_special_tokens': ['[START]', '[END]']}\n",
    "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    vocab_size = tokenizer.vocab_size + num_added_toks\n",
    "\n",
    "    return tokenizer, vocab_size\n",
    "\n",
    "tokenizer, vocab_size = get_tokenizer()\n",
    "\n",
    "config = model_config_factory(\"encoder_decoder_lg\")\n",
    "model = VLPForFeatureExtraction(model_dim=config[\"model_dim\"],\n",
    "                      num_layers=config[\"num_layers\"],\n",
    "                      num_heads=config[\"num_heads\"],\n",
    "                      ff_dim=config[\"ff_dim\"],\n",
    "                      feature_map_size=config[\"feature_map_size\"],\n",
    "                      dropout=0.0)\n",
    "model_state = torch.load(\"../best_model_wiki_enc_sota.pth\")[\"model_state\"]\n",
    "model.load_state_dict(model_state, strict=False)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaf506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../fonts/ubuntu_fonts.txt\", \"r\") as f:\n",
    "    fonts_lines = f.readlines()\n",
    "\n",
    "invalid_font_families = [\n",
    "    \"kacst\",\n",
    "    \"lohit\",\n",
    "    \"samyak\",\n",
    "]\n",
    "\n",
    "invalid_fonts = [\n",
    "    '/usr/share/fonts/type1/urw-base35/D050000L.t1',\n",
    "    '/usr/share/fonts/opentype/urw-base35/D050000L.otf',\n",
    "    '/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf',\n",
    "    '/usr/share/fonts/truetype/Gubbi/Gubbi.ttf',\n",
    "    '/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf',\n",
    "    '/usr/share/fonts/truetype/sinhala/lklug.ttf',\n",
    "    '/usr/share/fonts/truetype/Navilu/Navilu.ttf',\n",
    "    '/usr/share/fonts/truetype/openoffice/opens___.ttf',\n",
    "    '/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf',\n",
    "    '/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf',\n",
    "    '/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf',\n",
    "    '/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf',\n",
    "    '/usr/share/fonts/type1/urw-base35/StandardSymbolsPS.t1',\n",
    "    '/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf',\n",
    "    '/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf',\n",
    "    '/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf',\n",
    "    '/usrà¦¤à¦¿',\n",
    "    '/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf'\n",
    "]\n",
    "\n",
    "processed_fonts = []\n",
    "for f_l in fonts_lines:\n",
    "    font_path = f_l.split(\":\")[0]\n",
    "    if font_path in invalid_fonts or any(i_f in font_path.lower() for i_f in invalid_font_families):\n",
    "            continue\n",
    "    processed_fonts.append(font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c45373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large (up to 140 words)\n",
    "font_category_distributions = {\n",
    "    \"small\": (30, 30, 55),\n",
    "    \"medium\": (23, 30, 65), # 30\n",
    "    \"large\": (20, 30, 75)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23655cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_coords(im_dims, text_dims, align):\n",
    "    im_width, im_height = im_dims\n",
    "    text_width, text_height = text_dims\n",
    "    if align==\"center\":\n",
    "        x_text = (im_width - text_width) / 2\n",
    "        y_text = (im_height - text_height) / 2\n",
    "    elif align==\"right\":\n",
    "        x_text = im_width - text_width - 10\n",
    "        y_text = 10\n",
    "    elif align==\"down\":\n",
    "        x_text = (im_width - text_width) / 2\n",
    "        y_text = im_height - text_height - 10\n",
    "    elif align==\"up\":\n",
    "        x_text = (im_width - text_width) / 2\n",
    "        y_text = 10\n",
    "    # align left\n",
    "    else:\n",
    "        x_text = 10\n",
    "        y_text = 10\n",
    "        \n",
    "    x_text, y_text = min(4, x_text), min(4, y_text)\n",
    "    return x_text, y_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1589ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import textwrap\n",
    "\n",
    "ALIGNMENTS = [\"center\", \"left\", \"right\", \"down\", \"up\"]\n",
    "\n",
    "def get_text_category(num_tokens):\n",
    "    if num_tokens <= 50:\n",
    "        return \"small\"\n",
    "    elif num_tokens <= 100:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "    \n",
    "def sample_random_font():\n",
    "    return random.choice(processed_fonts)\n",
    "\n",
    "def sample_random_alignment():\n",
    "    return random.choices(ALIGNMENTS, weights=[0.25, 0.2, 0.1, 0.2, 0.25])[0]\n",
    "\n",
    "def sample_fs_and_tw(text_category):\n",
    "    font_size, min_text_width, max_text_width = font_category_distributions[text_category]\n",
    "    return font_size, random.randrange(min_text_width, max_text_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874ee5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(text,\n",
    "                 filename,\n",
    "                 image_size=512,\n",
    "                 font=\"arial.ttf\",\n",
    "                 font_size=20,\n",
    "                 bg_color=(255, 255, 255),\n",
    "                 bg='white',\n",
    "                 align=\"left\",\n",
    "                 width=636,\n",
    "                 height=636,\n",
    "                 text_width=40,\n",
    "                 resize=True,\n",
    "                 save_image=True):\n",
    "    font_size = int(font_size / 1.5)\n",
    "\n",
    "    # text width for wrapping\n",
    "    text = '\\n'.join(textwrap.wrap(text, width=text_width))  #, width=18\n",
    "    font = ImageFont.truetype(font, font_size)\n",
    "\n",
    "    image = Image.new(mode=\"RGB\", size=(width, height),\n",
    "                      color=\"white\")  # (700, 620)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    l, t, r, b = draw.multiline_textbbox((0, 0), text, font=font)\n",
    "    l_offset = abs(l) + 10\n",
    "    t_offset = abs(t) + 10\n",
    "    l = l_offset\n",
    "    t = t_offset\n",
    "    r += l_offset\n",
    "    b += t_offset\n",
    "    draw.text((l, t), text, font=font, fill=\"black\")\n",
    "    image = image.crop((0, 0, r + 10, b + 10))\n",
    "\n",
    "    if resize:\n",
    "        image = image.resize((image_size, image_size), Image.Resampling.LANCZOS)\n",
    "    if save_image:\n",
    "        image.save(filename)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202e633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/wavelet/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27005a11d8b9441bb7b471eed52be51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635419e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "def prep_image(text, tokenizer, max_text_len, device=None, image_size=512):\n",
    "    if not device:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    num_tokens = len(word_tokenize(text))\n",
    "    text_category = get_text_category(num_tokens)\n",
    "\n",
    "    font_path = sample_random_font()\n",
    "    font_size, text_width = sample_fs_and_tw(text_category)\n",
    "    alignment = sample_random_alignment()\n",
    "    \n",
    "    image = create_image(\n",
    "                text,\n",
    "                font=font_path,\n",
    "                filename=None,\n",
    "                bg_color=(255, 255, 255),\n",
    "                bg='white',\n",
    "                align=alignment,\n",
    "                font_size=font_size,\n",
    "                text_width=text_width,\n",
    "                resize=True,\n",
    "                save_image=False)\n",
    "    image = Resize((image_size, image_size))(image)\n",
    "    return F.to_tensor(image).to(device).unsqueeze(0)\n",
    "\n",
    "\n",
    "def predict_text(\n",
    "    model,\n",
    "    text,\n",
    "    tokenizer,\n",
    "    max_text_len,\n",
    "    image_size=512,\n",
    "    device=None,\n",
    "):\n",
    "    image = prep_image(text, tokenizer, max_text_len)\n",
    "    out = model(image)\n",
    "    return out\n",
    "\n",
    "def predict(\n",
    "    model,\n",
    "    images\n",
    "):\n",
    "    out = model(images)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9325b4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa258cc19fe94649ba5beccc5da4fa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "for instance in tqdm(dataset[\"train\"]):\n",
    "    if len(word_tokenize(instance[\"text\"])) > 144:\n",
    "        continue\n",
    "    data.append({\"text\": instance[\"text\"], \"label\": instance[\"label\"]})\n",
    "\n",
    "df_train = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94cda754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would put this at the top of my list of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whoever wrote the screenplay for this movie ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My interest in Dorothy Stratten caused me to p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think I will make a movie next weekend. Oh w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>This movie really kicked some ass. I watched i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>With the mixed reviews this got I wasn't expec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>Very smart, sometimes shocking, I just love it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     If only to avoid making this type of film in t...      0\n",
       "1     I would put this at the top of my list of film...      0\n",
       "2     Whoever wrote the screenplay for this movie ob...      0\n",
       "3     My interest in Dorothy Stratten caused me to p...      0\n",
       "4     I think I will make a movie next weekend. Oh w...      0\n",
       "...                                                 ...    ...\n",
       "5208  This movie really kicked some ass. I watched i...      1\n",
       "5209  With the mixed reviews this got I wasn't expec...      1\n",
       "5210  Very smart, sometimes shocking, I just love it...      1\n",
       "5211  A hit at the time but now better categorised a...      1\n",
       "5212  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[5213 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cda08697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed527301efcd400583dde6fe5fc658a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def extract_embedding(text):\n",
    "    emb = predict_text(model, text, tokenizer, 144)\n",
    "    return emb[0].cpu().detach().tolist()\n",
    "\n",
    "df_train[\"embedding\"] = df_train.text.progress_apply(extract_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a94989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(df_train.embedding.tolist())\n",
    "labels = df_train.label.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f8e6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 4170 4170\n",
      "test 1043 1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wavelet/projects/vlp/.vlp/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7785234899328859\n",
      "Confusion matrix: \n",
      " [[386 120]\n",
      " [111 426]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       506\n",
      "           1       0.78      0.79      0.79       537\n",
      "\n",
      "    accuracy                           0.78      1043\n",
      "   macro avg       0.78      0.78      0.78      1043\n",
      "weighted avg       0.78      0.78      0.78      1043\n",
      "\n",
      "Classification report train: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1920\n",
      "           1       0.81      0.83      0.82      2250\n",
      "\n",
      "    accuracy                           0.80      4170\n",
      "   macro avg       0.80      0.80      0.80      4170\n",
      "weighted avg       0.80      0.80      0.80      4170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"train\", X_train.shape[0], len(y_train))\n",
    "print(\"test\", X_test.shape[0], len(y_test))\n",
    " \n",
    "pca = PCA(n_components=300)\n",
    "# clf = LinearSVC(multi_class=\"ovr\", C=0.1, max_iter=1000, random_state=42)\n",
    "clf = LogisticRegression()\n",
    "clf = CalibratedClassifierCV(clf)\n",
    "# pipe = Pipeline(steps=[(\"pca\", pca), (\"clf\", clf)])\n",
    "pipe = Pipeline(steps=[(\"clf\", clf)])\n",
    " \n",
    "# Traing a classifer\n",
    "pipe.fit(X_train, y_train)\n",
    " \n",
    "# Evaluate the classifier\n",
    "y_pred = pipe.predict(X_test)\n",
    " \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    " \n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "print(\"Classification report: \\n\", class_report)\n",
    " \n",
    "y_pred_train = pipe.predict(X_train)\n",
    "class_report = classification_report(y_train, y_pred_train)\n",
    "print(\"Classification report train: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed321c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLP\n",
    "\n",
    "Accuracy:  0.7785234899328859\n",
    "Confusion matrix: \n",
    " [[386 120]\n",
    " [111 426]]\n",
    "Classification report: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.78      0.76      0.77       506\n",
    "           1       0.78      0.79      0.79       537\n",
    "\n",
    "    accuracy                           0.78      1043\n",
    "   macro avg       0.78      0.78      0.78      1043\n",
    "weighted avg       0.78      0.78      0.78      1043\n",
    "\n",
    "Classification report train: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.79      0.77      0.78      1920\n",
    "           1       0.81      0.83      0.82      2250\n",
    "\n",
    "    accuracy                           0.80      4170\n",
    "   macro avg       0.80      0.80      0.80      4170\n",
    "weighted avg       0.80      0.80      0.80      4170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "Accuracy:  0.8207094918504314\n",
    "Confusion matrix: \n",
    " [[420  86]\n",
    " [101 436]]\n",
    "Classification report: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.83      0.82       506\n",
    "           1       0.84      0.81      0.82       537\n",
    "\n",
    "    accuracy                           0.82      1043\n",
    "   macro avg       0.82      0.82      0.82      1043\n",
    "weighted avg       0.82      0.82      0.82      1043\n",
    "\n",
    "Classification report train: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.83      0.83      1920\n",
    "           1       0.86      0.85      0.85      2250\n",
    "\n",
    "    accuracy                           0.84      4170\n",
    "   macro avg       0.84      0.84      0.84      4170\n",
    "weighted avg       0.84      0.84      0.84      4170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy glove\n",
    "\n",
    "Accuracy:  0.840843720038351\n",
    "Confusion matrix: \n",
    " [[417  89]\n",
    " [ 77 460]]\n",
    "Classification report: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.82      0.83       506\n",
    "           1       0.84      0.86      0.85       537\n",
    "\n",
    "    accuracy                           0.84      1043\n",
    "   macro avg       0.84      0.84      0.84      1043\n",
    "weighted avg       0.84      0.84      0.84      1043\n",
    "\n",
    "Classification report train: \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.84      0.85      1920\n",
    "           1       0.87      0.88      0.88      2250\n",
    "\n",
    "    accuracy                           0.86      4170\n",
    "   macro avg       0.86      0.86      0.86      4170\n",
    "weighted avg       0.86      0.86      0.86      4170\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
